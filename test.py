import SETICrawler as SC
import sys


#url = SC.HOSTS_URL+'1000'
#soup = SC.GetSoup(url).getText()

s = [None]*3
a, b, c = s
#print(a)
print(s)

""" findindex = lambda self,i,value:sorted(self,key=lambda x:x[i]!=value)[0]

data = [['User ID', '205'], ['SETI@home member since', '7 Nov 2003'], ['Country', 'Czech Republic'], ['Total credit', '0'], ['Recent average credit', '0.00'], ['SETI@home classic CPU time', '17,007,914 hours'], ['Computers', 'View']]
test = []*3
test.append(None)
print(test.append(nan)) """